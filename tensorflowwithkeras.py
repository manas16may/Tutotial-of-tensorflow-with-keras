# -*- coding: utf-8 -*-
"""tensorflowwithkeras.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AL32lQS-q48TfEzKPvof_LUe_0GLVlRj
"""

import numpy as np
from random import randint
from sklearn.utils import shuffle
from sklearn.preprocessing import MinMaxScaler

train_labels=[]
train_samples=[]

for i in range(50):
  random_younger=randint(13,64)
  train_samples.append(random_younger)
  train_labels.append(1)
  
  random_older=randint(65,100)
  train_samples.append(random_older)
  train_labels.append(0)

for i in range(1000):
  random_younger=randint(13,64)
  train_samples.append(random_younger)
  train_labels.append(0)
  
  random_older=randint(65,100)
  train_samples.append(random_older)
  train_labels.append(1)

test_labels=[]
test_samples=[]
for i in range(10):
  random_younger=randint(13,64)
  test_samples.append(random_younger)
  test_labels.append(1)
  
  random_older=randint(65,100)
  test_samples.append(random_older)
  test_labels.append(0)

for i in range(200):
  random_younger=randint(13,64)
  test_samples.append(random_younger)
  test_labels.append(0)
  
  random_older=randint(65,100)
  test_samples.append(random_older)
  test_labels.append(1)

for i in train_samples:
  print(i)

train_labels=np.array(train_labels)
train_samples=np.array(train_samples)
train_labels,train_samples=shuffle(train_labels,train_samples)

test_labels=np.array(test_labels)
test_samples=np.array(test_samples)
test_labels,test_samples=shuffle(test_labels,test_samples)

scaler_test_samples=scaler.transform(test_samples.reshape(-1,1))

scaler=MinMaxScaler(feature_range=(0,1))
scaler_train_samples=scaler.fit_transform(train_samples.reshape(-1,1))

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
#from tensorflow.python.keras.models import Dense
from keras.layers.core import Activation,Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import categorical_crossentropy

model=Sequential([
                  Dense(units=16,input_shape=(1,),activation='relu'),
                  Dense(units=32,activation='relu'),
                  Dense(units=2,activation='softmax')
])

model.compile(optimizer=Adam(learning_rate=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])
history = model.fit(scaler_train_samples, train_labels,
                    batch_size=10,
                    epochs=30,shuffle=True,verbose=2)

model.summary()

model.compile(optimizer=Adam(learning_rate=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])
history = model.fit(scaler_train_samples, train_labels,
                    batch_size=10,validation_split=0.1,
                    epochs=30,shuffle=True,verbose=2)

predictions=model.predict(scaler_test_samples,batch_size=10,verbose=0)
rpredictions=np.argmax(predictions,axis=1)

